# Application Flow Diagram

## Startup Sequence

```
1. User runs: npm start
        â†“
2. Electron launches
        â†“
3. Main Process (main.js) starts
        â†“
4. Creates BrowserWindow (1200x800)
        â†“
5. Loads renderer/index.html
        â†“
6. Starts 3 services:
   â€¢ service-a.start()
   â€¢ service-b.start()
   â€¢ service-c.start()
        â†“
7. Services begin auto-generating requests
```

## Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service A  â”‚ â”€â”€â”
â”‚ (15% error) â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service B  â”‚ â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚ Metrics          â”‚
â”‚ (10% error) â”‚   â”‚     â”‚ Collector        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚ (recordMetric)   â”‚
                  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚               â”‚
â”‚  Service C  â”‚ â”€â”€â”˜               â”‚ Store in
â”‚ (20% error) â”‚                   â”‚ memory array
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Metrics Array    â”‚
                          â”‚ [{service, ts,   â”‚
                          â”‚   latency, code}]â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚ On request
                                    â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Metrics          â”‚
                          â”‚ Aggregator       â”‚
                          â”‚ (calculate)      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚ Returns
                                    â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ {                â”‚
                          â”‚   service-a: {   â”‚
                          â”‚     avgLatency,  â”‚
                          â”‚     errorRate,   â”‚
                          â”‚     requestCount â”‚
                          â”‚   },             â”‚
                          â”‚   service-b: ... â”‚
                          â”‚   service-c: ... â”‚
                          â”‚ }                â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## IPC Communication Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Renderer Process           â”‚
â”‚  (renderer/dashboard.js)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ (1) Every 2 seconds
           â”‚     ipcRenderer.invoke('get-metrics')
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main Process (main.js)     â”‚
â”‚  ipcMain.handle(...)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ (2) Call aggregator
           â”‚     metricsAggregator.getAggregatedMetrics()
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Returns aggregated data    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ (3) Send back to renderer
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard updates UI       â”‚
â”‚  â€¢ Update metric values     â”‚
â”‚  â€¢ Change card colors       â”‚
â”‚  â€¢ Update status indicators â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## User Interaction: Simulate Traffic

```
User clicks "Simulate Traffic" button
           â†“
Renderer: ipcRenderer.invoke('simulate-traffic')
           â†“
Main: ipcMain.handle('simulate-traffic', ...)
           â†“
Generate 10 random service requests:
  â€¢ Pick random service (A, B, or C)
  â€¢ Call service.simulateRequest()
  â€¢ Service generates latency & status
  â€¢ Records metric automatically
           â†“
Return success to renderer
           â†“
Renderer: Wait 500ms
           â†“
Renderer: Update metrics display
           â†“
Dashboard shows new values
```

## Metrics Calculation Details

### Average Latency
```javascript
Input:  [450ms, 650ms, 850ms]
Calculation:
  sum = 450 + 650 + 850 = 1950
  count = 3
  avg = 1950 / 3 = 650ms
Output: 650 ms
```

### Error Rate
```javascript
Input:  [200, 200, 500, 200, 500]
Calculation:
  errors = count(status >= 500) = 2
  total = 5
  rate = (2 / 5) Ã— 100 = 40%
Output: 40.00%
```

### Request Count
```javascript
Input:  Array of metrics
Calculation:
  count = metrics.filter(m => m.serviceName === 'service-a').length
Output: Integer count
```

## Alert State Determination

```
For each service:
  â”Œâ”€ Check latency and error rate
  â”‚
  â”œâ”€ If latency >= 800ms OR errorRate >= 20%
  â”‚  â””â”€â–¶ State = CRITICAL (ï¿½ï¿½)
  â”‚       â€¢ Card border: red
  â”‚       â€¢ Status dot: red
  â”‚       â€¢ Metrics highlighted: red
  â”‚
  â”œâ”€ Else if latency >= 600ms OR errorRate >= 10%
  â”‚  â””â”€â–¶ State = WARNING (ğŸŸ¡)
  â”‚       â€¢ Card border: orange
  â”‚       â€¢ Status dot: orange
  â”‚       â€¢ Metrics highlighted: orange
  â”‚
  â””â”€ Else
     â””â”€â–¶ State = NORMAL (ğŸŸ¢)
          â€¢ Card: white
          â€¢ Status dot: green
          â€¢ Metrics: default color
```

## Service Generation Pattern

```
Service A:
  setInterval(() => {
    latency = random(0-1000ms)
    status = random() < 0.15 ? 500 : 200
    wait(latency)
    recordMetric('service-a', latency, status)
  }, 2000-3000ms)

Service B:
  setInterval(() => {
    latency = random(0-1000ms)
    status = random() < 0.10 ? 500 : 200
    wait(latency)
    recordMetric('service-b', latency, status)
  }, 2500-4000ms)

Service C:
  setInterval(() => {
    latency = random(0-1000ms)
    status = random() < 0.20 ? 500 : 200
    wait(latency)
    recordMetric('service-c', latency, status)
  }, 3000-5000ms)
```

## Memory Management

```
Metrics Array:
  â€¢ Add new metric â†’ push to array
  â€¢ If array.length > 1000
    â””â”€â–¶ Remove oldest metric (shift)
  â€¢ Prevents memory growth
  â€¢ Rolling window of last 1000 metrics
```

## UI Update Cycle

```
Page Load
    â†“
Initialize
    â†“
Set interval (2000ms)
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Fetch metricsâ”‚â—€â”€â”€â”€â”€â”€â”
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
           â”‚              â”‚
           â–¼              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚ Update UI    â”‚      â”‚
    â”‚ â€¢ Values     â”‚      â”‚
    â”‚ â€¢ Colors     â”‚      â”‚
    â”‚ â€¢ Status     â”‚      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
           â”‚              â”‚
           â–¼              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚ Wait 2 secs  â”‚      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
           â”‚              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Error Simulation Logic

```
When service generates request:

random_value = Math.random()  // 0.0 to 1.0

If random_value < error_threshold:
    status = 500  // Internal Server Error
Else:
    status = 200  // OK

Example (Service A with 15% error rate):
    if (Math.random() < 0.15) {
        status = 500;  // ~15% of time
    } else {
        status = 200;  // ~85% of time
    }
```

## Complete Request Lifecycle

```
1. Service timer triggers
      â†“
2. Generate random latency (0-1000ms)
      â†“
3. Generate random status (200 or 500)
      â†“
4. Simulate delay (wait for latency duration)
      â†“
5. Call metricsCollector.recordMetric()
      â†“
6. Metric stored in memory array
      â†“
7. (2 seconds later) Dashboard requests metrics
      â†“
8. Aggregator calculates statistics
      â†“
9. Dashboard receives and displays
      â†“
10. User sees updated metrics
```

## Technology Stack Flow

```
User Interface
    â†• HTML/CSS/JavaScript
Renderer Process
    â†• IPC (Electron)
Main Process
    â†• require()
Node.js Modules
    â€¢ Services
    â€¢ Observer
    â†• In-Memory
JavaScript Objects
```

---

This flow diagram shows the complete architecture and data flow of the Distributed Systems Observability Dashboard application.
